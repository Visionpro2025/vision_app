# ============================================
# üìå STEP 2C: VERIFICACI√ìN AVANZADA DE CONTENIDO
# Detecta informaci√≥n ileg√≠tima, falsa y generada por IA
# ============================================

from __future__ import annotations
from typing import Dict, Any, List
from app_vision.engine.contracts import Step, StepContext, StepError
from app_vision.engine.fsm import register_step
from app_vision.modules.content_verification import ContentVerificationEngine
from app_vision.modules.role_guard import enforce_orchestrator_role

@register_step("ContentVerificationStep")
class ContentVerificationStep(Step):
    """
    Step que verifica contenido avanzado para detectar:
    - Informaci√≥n generada por IA
    - Contenido falsificado o inventado
    - Inconsistencias temporales
    - Metadatos corruptos
    - Fuentes no confiables
    """
    
    def __init__(self):
        self.verification_engine = ContentVerificationEngine()
    
    def run(self, ctx: StepContext, data: Dict[str, Any]) -> Dict[str, Any]:
        # Verificar rol de orquestador
        enforce_orchestrator_role(ctx, data, "ContentVerificationStep")
        
        # Obtener art√≠culos seleccionados del paso anterior
        selected_articles = data.get("selected_articles") or []
        if not selected_articles:
            raise StepError("InputError", "No hay art√≠culos seleccionados para verificar.")
        
        # Verificar contenido
        verification_results = self.verification_engine.verify_content(selected_articles)
        
        # Separar art√≠culos leg√≠timos de los ileg√≠timos
        legitimate_articles = []
        illegitimate_articles = []
        
        for i, (article, result) in enumerate(zip(selected_articles, verification_results)):
            if result.is_legitimate:
                legitimate_articles.append(article)
            else:
                illegitimate_articles.append({
                    "article": article,
                    "verification_result": result.__dict__,
                    "rejection_reasons": result.verification_reasons
                })
        
        # Calcular m√©tricas
        total_articles = len(selected_articles)
        legitimate_count = len(legitimate_articles)
        illegitimate_count = len(illegitimate_articles)
        
        # An√°lisis de razones de rechazo
        rejection_analysis = {
            "ai_generated": sum(1 for r in verification_results if r.ai_detection),
            "suspicious_content": sum(1 for r in verification_results if not r.temporal_coherence),
            "metadata_corrupted": sum(1 for r in verification_results if not r.metadata_integrity),
            "low_source_reliability": sum(1 for r in verification_results if r.source_reliability < 0.5)
        }
        
        # Verificar si hay suficientes art√≠culos leg√≠timos
        min_legitimate = data.get("min_legitimate_articles", 10)
        if legitimate_count < min_legitimate:
            raise StepError(
                "InsufficientLegitimateContent",
                f"Solo {legitimate_count} art√≠culos leg√≠timos de {total_articles} "
                f"(m√≠nimo requerido: {min_legitimate}). "
                f"Razones: {rejection_analysis}"
            )
        
        # Generar reporte de verificaci√≥n
        verification_report = {
            "total_verified": total_articles,
            "legitimate_count": legitimate_count,
            "illegitimate_count": illegitimate_count,
            "legitimacy_rate": legitimate_count / total_articles if total_articles > 0 else 0,
            "rejection_analysis": rejection_analysis,
            "verification_details": [
                {
                    "title": r.article.get("title", "Sin t√≠tulo"),
                    "is_legitimate": r.is_legitimate,
                    "confidence_score": r.confidence_score,
                    "ai_detection": r.ai_detection,
                    "temporal_coherence": r.temporal_coherence,
                    "metadata_integrity": r.metadata_integrity,
                    "source_reliability": r.source_reliability,
                    "reasons": r.verification_reasons
                }
                for r in verification_results
            ]
        }
        
        return {
            "legitimate_articles": legitimate_articles,
            "illegitimate_articles": illegitimate_articles,
            "verification_report": verification_report,
            "verification_passed": True,
            "legitimacy_confidence": sum(r.confidence_score for r in verification_results) / len(verification_results) if verification_results else 0
        }





